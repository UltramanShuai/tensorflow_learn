{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: tf.reduce_mean(tf.square(y_-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 反向传播以减小loss为目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)  \n",
    "train_step=tf.train.MomentumOptimizer(learning_rate,momentum).minimuze(loss)  \n",
    "train_step=tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学习率： 决定参数每次更新的幅度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH_SIZE 是一次喂入多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "seed= 23455"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mtrand.RandomState at 0x2de4c8e4870>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建32行两列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.rand(32,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和小于1 为1 否则 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=[[int(x0+x1<1)] for (x0,x1) in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义输入和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tf.placeholder(tf.float32,shape=(None,2))\n",
    "y_= tf.placeholder(tf.float32,shape=(None,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Programmer\\Anaconda3\\envs\\python3_anaconda_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "w1= tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.square(y-y_))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "# train_step=tf.train.MomentumOptimizer(0.001,0.9).minimize(loss)\n",
    "#train_step=tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "501%500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:\n",
      " [[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "w2:\n",
      " [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "\n",
      "\n",
      "After 0 training step(s), loss on all data is 5.13118\n",
      "After 500 training step(s), loss on all data is 0.429111\n",
      "After 1000 training step(s), loss on all data is 0.409789\n",
      "After 1500 training step(s), loss on all data is 0.399923\n",
      "After 2000 training step(s), loss on all data is 0.394146\n",
      "After 2500 training step(s), loss on all data is 0.390597\n",
      "After 3000 training step(s), loss on all data is 0.388336\n",
      "After 3500 training step(s), loss on all data is 0.386855\n",
      "After 4000 training step(s), loss on all data is 0.385863\n",
      "After 4500 training step(s), loss on all data is 0.385187\n",
      "After 5000 training step(s), loss on all data is 0.384719\n",
      "After 5500 training step(s), loss on all data is 0.384391\n",
      "After 6000 training step(s), loss on all data is 0.38416\n",
      "After 6500 training step(s), loss on all data is 0.383995\n",
      "After 7000 training step(s), loss on all data is 0.383877\n",
      "After 7500 training step(s), loss on all data is 0.383791\n",
      "After 8000 training step(s), loss on all data is 0.383729\n",
      "After 8500 training step(s), loss on all data is 0.383684\n",
      "After 9000 training step(s), loss on all data is 0.383652\n",
      "After 9500 training step(s), loss on all data is 0.383628\n",
      "\n",
      "\n",
      "w1:\n",
      " [[-0.6916735   0.8159269   0.09629341]\n",
      " [-2.3433847  -0.10742698  0.5854707 ]]\n",
      "w2:\n",
      " [[-0.08710446]\n",
      " [ 0.8164447 ]\n",
      " [-0.05229824]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op= tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(\"w1:\\n\",sess.run(w1))\n",
    "    print(\"w2:\\n\",sess.run(w2))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    STEPS = 10000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % len(X)\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict= {x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 500 ==0:\n",
    "            total_loss= sess.run(loss,feed_dict={x:X,y_:Y})\n",
    "            print(\"After %d training step(s), loss on all data is %g\"%(i,total_loss))\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(\"w1:\\n\", sess.run(w1))\n",
    "    print(\"w2:\\n\",sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
